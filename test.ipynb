{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "\n",
    "model = YOLO(\"runs/detect/train53/weights/last.pt\")\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"data.yaml\", epochs=100, device= \"0\", batch= -1)  # train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model = YOLO('yoloModels/collab3_last.pt')\n",
    "\n",
    "def process_images(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Run the YOLO model on all PNG images in the input folder and save the results in the output folder.\n",
    "\n",
    "    :param input_folder: Path to the folder containing input PNG images.\n",
    "    :param output_folder: Path to the folder to save output images.\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith('.png'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Run inference on the image\n",
    "            results = model(input_path)\n",
    "\n",
    "\n",
    "            # Process results and save the output image\n",
    "            for result in results:\n",
    "                result.save(filename=output_path)\n",
    "                print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"testTif\"\n",
    "output_folder = \"test_colab3\"\n",
    "process_images(input_folder, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize openAI api to read number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"TMG_OpenAI_API\"))\n",
    "\n",
    "\n",
    "def readNumber (base64_image):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"This image might have a number in it. Can you tell me what number it is and only that number? if there is no number can you respond with no number. Numbers maybe rotated, if the numbers are rotated can you respond with no number?\"},\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \n",
    "            },\n",
    "            },\n",
    "        ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    )\n",
    "\n",
    "    # print(response.choices[0].message.content)\n",
    "    return (response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 28 dimensions, 1 hole, 5 dias, 2 gd&ts, 48.0ms\n",
      "Speed: 4.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "90.0\n",
      "3\n",
      "75.0\n",
      "5\n",
      "Value returned is not a number: no number\n",
      "6\n",
      "80.0\n",
      "7\n",
      "Value returned is not a number: No number\n",
      "9\n",
      "310.0\n",
      "10\n",
      "215.0\n",
      "11\n",
      "8.0\n",
      "13\n",
      "Value returned is not a number: No number\n",
      "14\n",
      "35.0\n",
      "15\n",
      "Value returned is not a number: No number.\n",
      "16\n",
      "Value returned is not a number: No number.\n",
      "17\n",
      "53.0\n",
      "18\n",
      "Value returned is not a number: No number\n",
      "19\n",
      "270.0\n",
      "20\n",
      "Value returned is not a number: No number.\n",
      "21\n",
      "Value returned is not a number: No number.\n",
      "22\n",
      "Value returned is not a number: No number.\n",
      "23\n",
      "125.0\n",
      "24\n",
      "136.0\n",
      "25\n",
      "Value returned is not a number: No number\n",
      "26\n",
      "Value returned is not a number: No number\n",
      "28\n",
      "Value returned is not a number: No number\n",
      "30\n",
      "Value returned is not a number: No number\n",
      "31\n",
      "170.0\n",
      "32\n",
      "190.5\n",
      "33\n",
      "Value returned is not a number: No number.\n",
      "35\n",
      "Value returned is not a number: No number.\n",
      "[90.0, 75.0, '440', 80.0, 'No number.', 310.0, 215.0, 8.0, '343', 35.0, '360', '20', 53.0, '75', 270.0, '410', '46', '37.5', 125.0, 136.0, '46', '117', '1020', '221', 170.0, 190.5, '230', 'No number.']\n",
      "Image saved with labels as labeled_image2.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import base64\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yoloModels/colab_2_last.pt')\n",
    "\n",
    "# Load the image\n",
    "image_path = 'test/22028-D-254-0_page_1.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "dimensions = []\n",
    "\n",
    "def is_float(value):\n",
    "    \"\"\" Check if the value is an integer. \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def encode_image(image_path):\n",
    "    _, buffer = cv2.imencode(\".jpg\", image_path)\n",
    "    return base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "# View results\n",
    "for r in results:\n",
    "    boxes = r.boxes.cpu().numpy()    # print the Boxes object containing the detection bounding boxes\n",
    "\n",
    "    XYcoords = boxes.xyxy\n",
    "    dimClass = boxes.cls\n",
    "    # print(XYcoords)\n",
    "    # print(dimClass)\n",
    "\n",
    "    # Iterate through the array of bounding boxes\n",
    "    dimCount = 1\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(XYcoords, 1):\n",
    "        \n",
    "        if dimClass[i-1] == 0:\n",
    "        \n",
    "            # Convert coordinates to integers (if they are not already)\n",
    "            xmin, ymin, xmax, ymax = map(int, (xmin, ymin, xmax, ymax))\n",
    "\n",
    "            # Crop the region of interest (ROI) from the image\n",
    "            roi = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            # Resize image \n",
    "            resized_image = cv2.resize(roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "            # print(\"Image shape:\", resized_image.shape)\n",
    "\n",
    "            #do thresholding\n",
    "            gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            _, thresholded_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "                    #general label\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "\n",
    "            # # Define label position (slightly above the top-left corner of the bounding box)\n",
    "            label_position_gen = (xmin, ymin - 10) if ymin - 10 > 10 else (xmin, ymin + 20)\n",
    "            label_gen = f'{i}'\n",
    "            print(label_gen)\n",
    "\n",
    "            # Add label to the image\n",
    "            cv2.putText(image, label_gen, label_position_gen, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # encode image\n",
    "            encoded_img = encode_image(thresholded_image)\n",
    "\n",
    "            # print the value that openai reads\n",
    "            \n",
    "            dim = readNumber(encoded_img)\n",
    "            \n",
    "            try:\n",
    "            # Try to convert the result to a float\n",
    "                number = float(dim)\n",
    "                print(number)\n",
    "                dimensions.append(number)  # Append to the array if successful\n",
    "            except ValueError:\n",
    "            # Handle the case where dim is not a number (e.g., it's a string)\n",
    "                print(f\"Value returned is not a number: {dim}\")\n",
    "                # dimensions.append(f\"{label_gen}_n/a\")\n",
    "\n",
    "            # rotating the image\n",
    "\n",
    "                rotatedImg = cv2.rotate(thresholded_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "                encoded_img_rot = encode_image(rotatedImg)\n",
    "\n",
    "                dim_rotate = readNumber(encoded_img_rot)\n",
    "                dimensions.append(dim_rotate)\n",
    "\n",
    "\n",
    "            # Print or store the extracted text\n",
    "            # print(f\"Box {i}: {text.strip()}, Rotated: {text_rotated}\")\n",
    "\n",
    "    \n",
    "            cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "    cv2.destroyAllWindows()  # Close the window\n",
    "        \n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path = 'labeled_image2.png'\n",
    "    print(dimensions)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "    print(f\"Image saved with labels as {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
